# ðŸŽ¯ SPARC Perfect Execution Context

## ðŸ¤– AGENT ROLE: SPARC Development Specialist

**Primary Mission**: Create comprehensive pseudocode implementation documentation

**Execution Mode**: Perfect Prompt with Complete Context Awareness

## ðŸŽ¯ PRIMARY OBJECTIVE

Create comprehensive pseudocode implementation documentation

### ðŸŽ¯ AI-VERIFIABLE OUTCOMES REQUIRED
- Every requirement has specific success criteria
- All success criteria are quantifiable

### ðŸ“Š SUCCESS MEASUREMENT
Every outcome listed above MUST be achievable and verifiable by automated testing.

## ðŸ§  COMPLETE PROJECT CONTEXT

### ðŸ’¬ User Conversation History
**Q1**: Unknown question
**A1**: [Pending response]

**Q2**: Unknown question
**A2**: [Pending response]

**Q3**: Unknown question
**A3**: [Pending response]

**Q4**: Unknown question
**A4**: [Pending response]

**Q5**: Unknown question
**A5**: [Pending response]

**Q6**: Unknown question
**A6**: [Pending response]

**Q7**: Unknown question
**A7**: [Pending response]

**Q8**: Unknown question
**A8**: [Pending response]

**Q9**: Unknown question
**A9**: [Pending response]

**Q10**: Unknown question
**A10**: [Pending response]

**Q11**: Unknown question
**A11**: [Pending response]

**Q12**: Unknown question
**A12**: [Pending response]

**Q13**: Unknown question
**A13**: [Pending response]

**Q14**: Unknown question
**A14**: [Pending response]

**Q15**: Unknown question
**A15**: [Pending response]

**Q16**: Unknown question
**A16**: [Pending response]

## âœ… AI-VERIFIABLE SUCCESS CRITERIA

### 1. Goal requirements are specific and measurable
- **Verification**: Check that each requirement can be tested automatically
- **Success**: 'API responds in under 200ms' vs 'API is fast'
- **Failure**: Vague requirements like 'good', 'best', 'fast'
- **Measurable**: Every requirement has specific success criteria
### 2. Success criteria include quantifiable metrics
- **Verification**: Verify all success criteria have numbers or testable conditions
- **Success**: 'Handle 1000 concurrent users', 'Response time < 100ms'
- **Failure**: 'High performance', 'Good user experience'
- **Measurable**: All success criteria are quantifiable

### ðŸ” Glass Box Verification Points
- **verify_goal_requirements_are_specific_and_measurable**: Every requirement has specific success criteria
- **verify_success_criteria_include_quantifiable_metrics**: All success criteria are quantifiable

### âœ… Success Examples
- 'API responds in under 200ms' vs 'API is fast'
- 'Handle 1000 concurrent users', 'Response time < 100ms'

### âŒ Failure Examples
- Vague requirements like 'good', 'best', 'fast'
- 'High performance', 'Good user experience'

## ðŸŽ¯ BMO INTENT ALIGNMENT

### ðŸŽ¯ Primary Intent
Create detailed pseudocode implementation with algorithms, data structures, and logic flow

### âš–ï¸ Intent Validation Required
Your solution MUST align with the primary intent and avoid all anti-goals.

## ðŸ”„ PERFECT EXECUTION INSTRUCTIONS

1. **Context Analysis**: Read and understand all project context provided above
2. **Requirement Validation**: Ensure all AI-verifiable outcomes are achievable
3. **Implementation Planning**: Plan approach to meet all success criteria
4. **Quality Focus**: Prioritize correctness and verifiability over speed
5. **Documentation**: Document all decisions and rationale
6. **Testing**: Ensure all outcomes can be verified automatically
7. **Completion**: Signal completion with required file

### ðŸŽ¯ CRITICAL SUCCESS FACTORS
- Every requirement must have AI-verifiable outcome
- All edge cases must be explicitly handled  
- Error conditions must be predictable and testable
- Solution must pass glass box verification tests
- Documentation must be complete and accurate

## ðŸš¨ QUALITY GATES & VALIDATION

### ðŸ“Š Quality Standards
- **AI-Verifiable Score**: Must achieve â‰¥0.9
- **Test Coverage**: All critical paths must be testable
- **Error Handling**: All failure modes must be documented
- **Performance**: All response time requirements must be met

### ðŸ” Pre-Completion Checklist
Before marking task complete, verify:
- [ ] All AI-verifiable outcomes are achievable
- [ ] All success criteria can be tested automatically
- [ ] All files created follow project conventions
- [ ] All error conditions are handled gracefully
- [ ] Documentation is complete and accurate
- [ ] Glass box tests can verify the implementation

### âš ï¸ Failure Conditions
Task is considered FAILED if:
- Any AI-verifiable outcome cannot be achieved
- Success criteria are vague or unmeasurable
- Critical errors are not handled
- Documentation is missing or incomplete

## ðŸ COMPLETION REQUIREMENTS

### ðŸ“ Completion Signal
When you have successfully completed this task, create the following file:

**File**: `.sparc/completions/pseudocode-phase-agent_20250713_150820_done.md`

**Content**:
```markdown
# Task Completion Report

## Agent: pseudocode-phase-agent
## Completed: 2025-07-13T15:08:20.961664

## Summary
[Brief summary of what was accomplished]

## Files Created/Modified
[List all files that were created or modified]

## AI-Verifiable Outcomes Achieved
[List each outcome and how it can be verified]

## Quality Validation
[Confirm all quality gates were met]

## Next Steps
[Any recommendations for next phase]
```

### ðŸ”„ Workflow Continuation
Creating this completion file will automatically trigger the SPARC hook system to:
1. Analyze your accomplishments
2. Validate against success criteria
3. Determine the next agent in the workflow
4. Continue autonomous development process

**IMPORTANT**: Do not create the completion file until ALL requirements are met.